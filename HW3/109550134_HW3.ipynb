{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3: Decision Tree, AdaBoost and Random Forest\n",
    "In hw3, you need to implement decision tree, adaboost and random forest by using only numpy, then train your implemented model by the provided dataset. TA will use the on-hold test label to evaluate your model performance.\n",
    "\n",
    "Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling `sklearn.tree.DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Gini Index or Entropy is often used for measuring the “best” splitting of the data. Please compute the Entropy and Gini Index of provided data. Please use the formula from [page 5 of hw3 slides](https://docs.google.com/presentation/d/1kIe_-YZdemRMmr_3xDy-l0OS2EcLgDH7Uan14tlU5KE/edit#slide=id.gd542a5ff75_0_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste your implementations right here to check your result\n",
    "# (Of course you can add your classes not written here)\n",
    "import numpy as np\n",
    "\n",
    "# sequence: multiple rows\n",
    "def gini(sequence): \n",
    "    s = len(sequence) # seq's length\n",
    "    cls = np.unique(sequence) # class in seq\n",
    "    cls_dict = dict() # store class with corresponding amount\n",
    "    for item in sequence:\n",
    "        if(item in cls_dict):\n",
    "            cls_dict[ item ] += 1\n",
    "        else:\n",
    "            cls_dict[item] = 1\n",
    "    g = 1\n",
    "    for c in cls: # for each class\n",
    "        p = cls_dict[c]/s # probability of being the class\n",
    "        g -= pow(p,2) # gini -= p^2\n",
    "    return g\n",
    "\n",
    "\n",
    "def entropy(sequence):\n",
    "    s = len(sequence) # seq's length\n",
    "    cls = np.unique(sequence) # class in seq\n",
    "    cls_dict = dict() # store class with corresponding amount\n",
    "    for item in sequence:\n",
    "        if(item in cls_dict):\n",
    "            cls_dict[ item ] += 1\n",
    "        else:\n",
    "            cls_dict[item] = 1\n",
    "    e = 0\n",
    "    for c in cls: # for each class\n",
    "        p = cls_dict[c]/s # probability of being the class\n",
    "        e -= p*np.log2(p) # entropy -= p*log2(p)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = class 1,\n",
    "# 2 = class 2\n",
    "data = np.array([1,2,1,1,1,1,2,2,1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini of data is  0.4628099173553719\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini of data is \", gini(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of data is  0.9456603046006401\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy of data is \", entropy(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "It is a binary classifiation dataset that classify if price is high or not for a cell phone, the label is stored in `price_range` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 21)\n",
      "(300, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1583</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>942</td>\n",
       "      <td>1651</td>\n",
       "      <td>1704</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.8</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>1538</td>\n",
       "      <td>2459</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.7</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>1504</td>\n",
       "      <td>1799</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>164</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>873</td>\n",
       "      <td>1394</td>\n",
       "      <td>1944</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1649</td>\n",
       "      <td>1829</td>\n",
       "      <td>2855</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0           1583     1          2.1         1  11       0          14    0.7   \n",
       "1            745     1          0.6         1   5       0          35    0.8   \n",
       "2            832     0          0.7         1   2       1          39    0.7   \n",
       "3           1175     1          1.3         0   2       0          19    0.3   \n",
       "4            695     0          0.5         0  18       1          12    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        148        7  ...        942      1651  1704    17    13          2   \n",
       "1        102        8  ...         89      1538  2459    14     1         16   \n",
       "2        103        4  ...        125      1504  1799     5     2         11   \n",
       "3        164        7  ...        873      1394  1944     9     4          9   \n",
       "4        196        2  ...       1649      1829  2855    16    13          7   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        1             0     1            1  \n",
       "1        1             1     0            0  \n",
       "2        1             0     1            0  \n",
       "3        1             1     0            0  \n",
       "4        1             1     1            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('val.csv')\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Implement the Decision Tree algorithm (CART, Classification and Regression Trees) and trained the model by the given arguments, and print the accuracy score on the validation data. You should implement two arguments for the Decision Tree algorithm\n",
    "1. **criterion**: The function to measure the quality of a split. Your model should support `gini` for the Gini impurity and `entropy` for the information gain. \n",
    "2. **max_depth**: The maximum depth of the tree. If `max_depth=None`, then nodes are expanded until all leaves are pure. `max_depth=1` equals to split data once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nparray(input_df): # change dataframe to nparray\n",
    "    x = input_df.drop(labels=[\"price_range\"], axis=\"columns\")\n",
    "    x = x.values\n",
    "    y = input_df['price_range'].values\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
      "0              1583     1          2.1         1  11       0          14   \n",
      "1               745     1          0.6         1   5       0          35   \n",
      "2               832     0          0.7         1   2       1          39   \n",
      "3              1175     1          1.3         0   2       0          19   \n",
      "4               695     0          0.5         0  18       1          12   \n",
      "...             ...   ...          ...       ...  ..     ...         ...   \n",
      "1195           1872     1          0.5         1  14       0          49   \n",
      "1196           1239     0          1.2         1   5       1          52   \n",
      "1197           1195     1          1.1         1   2       1           8   \n",
      "1198            671     0          0.9         1  10       0          30   \n",
      "1199           1845     1          0.5         1  10       0          61   \n",
      "\n",
      "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
      "0       0.7        148        7  ...        942      1651  1704    17    13   \n",
      "1       0.8        102        8  ...         89      1538  2459    14     1   \n",
      "2       0.7        103        4  ...        125      1504  1799     5     2   \n",
      "3       0.3        164        7  ...        873      1394  1944     9     4   \n",
      "4       0.6        196        2  ...       1649      1829  2855    16    13   \n",
      "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
      "1195    0.2        139        7  ...         81      1389  3153    16    15   \n",
      "1196    0.9        122        2  ...        590       661   417     8     0   \n",
      "1197    0.9         80        6  ...        327      1001   643    14     2   \n",
      "1198    0.7        105        7  ...        852      1182  2504     6     4   \n",
      "1199    0.3         96        1  ...        292       695  1731     9     5   \n",
      "\n",
      "      talk_time  three_g  touch_screen  wifi  price_range  \n",
      "0             2        1             0     1            1  \n",
      "1            16        1             1     0            0  \n",
      "2            11        1             0     1            0  \n",
      "3             9        1             1     0            0  \n",
      "4             7        1             1     1            1  \n",
      "...         ...      ...           ...   ...          ...  \n",
      "1195          5        1             1     0            1  \n",
      "1196          6        1             0     1            0  \n",
      "1197         19        1             0     0            0  \n",
      "1198         15        1             0     0            1  \n",
      "1199          6        0             0     0            0  \n",
      "\n",
      "[1200 rows x 21 columns]\n",
      "591 609\n",
      "[1 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def g_or_e(sequence, criterion): #perform gini or entropy base on criterion\n",
    "    if(criterion=='gini'):\n",
    "        return gini(sequence)\n",
    "    else:\n",
    "        return entropy(sequence)\n",
    "\n",
    "def compute(t_cls, f_cls, criterion, cur): # compute infomation gain\n",
    "    prob_t = len(t_cls)/ (len(f_cls)+len(t_cls) ) #probability of true\n",
    "    n = g_or_e(t_cls, criterion)*prob_t + g_or_e(f_cls, criterion)*(1-prob_t) #multiply weight\n",
    "    return cur-n\n",
    "\n",
    "def tf_generator(x_data, y_data, i, v): # seperate true & false by feature and value\n",
    "    t = [] \n",
    "    f = []\n",
    "    for row, cls in zip(x_data, y_data):\n",
    "        if(row[i]>=v): # bool: v=1\n",
    "            t.append(cls)\n",
    "        else:\n",
    "            f.append(cls)\n",
    "    return t, f\n",
    "\n",
    "def tf_generator_x(x_data, y_data, i, v): # seperate true & false by feature and value\n",
    "    tx = [] \n",
    "    ty = []\n",
    "    fx = []\n",
    "    fy = []\n",
    "    for row, cls in zip(x_data, y_data):\n",
    "        if(row[i]>=v): # bool: v=1\n",
    "            tx.append(row)\n",
    "            ty.append(cls)\n",
    "        else:\n",
    "            fx.append(row)\n",
    "            fy.append(cls)\n",
    "    tx = np.array(tx)\n",
    "    ty = np.array(ty)\n",
    "    fx = np.array(fx)\n",
    "    fy = np.array(fy)\n",
    "    return tx, ty, fx, fy\n",
    "\n",
    "\n",
    "print(train_df)\n",
    "x_data, y_data = to_nparray(train_df) # transform data\n",
    "t_temp, f_temp = tf_generator(x_data, y_data, 1, 1)\n",
    "print(len(t_temp),len(f_temp))\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class d_node(): # decision node\n",
    "    def __init__(self, true, false, split_f):\n",
    "        self.true = true\n",
    "        self.false = false\n",
    "        self.split_f = split_f # split feature and value\n",
    "\n",
    "class l_node(): #leaf node\n",
    "    def __init__(self, sequence):\n",
    "        self.cls_pred = dict() # store class with corresponding amount\n",
    "        self.cls_pred = {1:0, 0:0}\n",
    "        for item in sequence:\n",
    "            if(item in self.cls_pred):\n",
    "                self.cls_pred[ item ] += 1\n",
    "            else:\n",
    "                self.cls_pred[item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, criterion='gini', max_depth=None, forest=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.tree = ' '\n",
    "        self.y_predict = []\n",
    "        self.gain = ' '\n",
    "        self.feature_n_val = ' '\n",
    "        self.for_ada_y_data = ' '\n",
    "        self.feature_pool_index = []\n",
    "        self.feature_pool = []\n",
    "        self.forest = forest\n",
    "        self.importance = np.zeros(20)\n",
    "        pass\n",
    "    \n",
    "    def pool(self, x_data, y_data): # all feature of data\n",
    "        for i in range(len(x_data[0]-1)):\n",
    "            v_of_feature_i = np.unique(x_data[:, i])\n",
    "            if(len(v_of_feature_i)==2): #bool\n",
    "                t, f = tf_generator(x_data, y_data, i, 1)\n",
    "                if(len(t)!=0 and len(f)!=0):\n",
    "                    self.feature_pool.append([i, 1])\n",
    "            else: #numeric\n",
    "                for v in v_of_feature_i:\n",
    "                    t, f = tf_generator(x_data, y_data, i, v)\n",
    "                    if(len(t)!=0 and len(f)!=0):\n",
    "                        self.feature_pool.append([i, v])\n",
    "        return len(self.feature_pool)\n",
    "\n",
    "    def split(self, x_data, y_data, criterion): # find best split with best infomation gain\n",
    "        best_gain = 0\n",
    "        best_feature_n_val = [] # store feature ol, val(bool=1)\n",
    "        cur = g_or_e(y_data, criterion) \n",
    "        count = 0 # index of feature\n",
    "        for i in range(len(x_data[0]-1)): # loop all features\n",
    "            v_of_feature_i = np.unique(x_data[:, i])\n",
    "            flag = True\n",
    "            if(len(v_of_feature_i)==2): #bool\n",
    "                \n",
    "                if(self.forest == True):\n",
    "                    if(count  not in self.feature_pool_index):\n",
    "                        flag = False\n",
    "                if(flag == True):\n",
    "                    t, f = tf_generator(x_data, y_data, i, 1)\n",
    "                    if(len(t)!=0 and len(f)!=0):\n",
    "                        temp_gain = compute(t, f, criterion, cur)\n",
    "                        if (temp_gain>best_gain):\n",
    "                            best_gain = temp_gain\n",
    "                            best_feature_n_val = [i, 1]\n",
    "                count+=1\n",
    "            else: #numeric\n",
    "                for v in v_of_feature_i:\n",
    "                    if(self.forest == True):\n",
    "                        if(count not in self.feature_pool_index):\n",
    "                            flag = False\n",
    "                    if(flag == True):\n",
    "                        t, f = tf_generator(x_data, y_data, i, v)\n",
    "                        if(len(t)!=0 and len(f)!=0):\n",
    "                            temp_gain = compute(t, f, criterion, cur)\n",
    "                            if (temp_gain>best_gain):\n",
    "                                best_gain = temp_gain\n",
    "                                best_feature_n_val = [i, v]\n",
    "                    flag = True\n",
    "                    count+=1\n",
    "        return best_gain, best_feature_n_val\n",
    "\n",
    "    def fitting(self, x_data, y_data, depth=0):\n",
    "\n",
    "        gain, feature_n_val = self.split(x_data, y_data, self.criterion) # find best split by self.split\n",
    "        self.gain = gain\n",
    "        self.feature_n_val = feature_n_val\n",
    "        if (gain==0 or depth==self.max_depth): # max depth or nothing learned\n",
    "            self.for_ada_y_data = y_data\n",
    "            return l_node(y_data) #leaf node\n",
    "        else: #still learning\n",
    "            tx, ty, fx, fy = tf_generator_x(x_data, y_data, feature_n_val[0], feature_n_val[1])\n",
    "            true = self.fitting(tx, ty, depth+1) # continue on its child node\n",
    "            false = self.fitting(fx, fy, depth+1)\n",
    "        \n",
    "        if(self.tree == ' '): self.tree = d_node(true, false, feature_n_val)\n",
    "        return d_node(true, false, feature_n_val) # decision node\n",
    "\n",
    "    def fit(self, x_data, y_data, depth=0): # fit using fitting\n",
    "        self.tree = self.fitting( x_data, y_data, depth=0)\n",
    "\n",
    "    def pred_row(self, row, node): #predict result of row\n",
    "\n",
    "        if (type(node)==l_node):\n",
    "            if(node.cls_pred[1]>=node.cls_pred[0]): # l_node class = true\n",
    "                self.y_predict.append(1)\n",
    "                return \n",
    "            else: # l_node class = false\n",
    "                self.y_predict.append(0)\n",
    "                return \n",
    "\n",
    "        i = node.split_f[0] # i\n",
    "        v = node.split_f[1] # v\n",
    "\n",
    "        if(row[i]>=v): #true\n",
    "            self.pred_row(row, node.true)\n",
    "        else: #false\n",
    "            self.pred_row(row, node.false)\n",
    "\n",
    "    def pred_row_print(self, row, node): #predict result of row\n",
    "        if (type(node)==l_node):\n",
    "            if(node.cls_pred[1]>=node.cls_pred[0]): # l_node class = true\n",
    "                row_pred = 1\n",
    "                return row_pred\n",
    "            else: # l_node class = false\n",
    "                row_pred = 0\n",
    "                return row_pred\n",
    "\n",
    "        i = node.split_f[0] # i\n",
    "        v = node.split_f[1] # v\n",
    "        if(row[i]>=v): #true\n",
    "            self.pred_row(row, node.true)\n",
    "        else: #false\n",
    "            self.pred_row(row, node.false)\n",
    "   \n",
    "    def predict(self, x_data): # predict 得出 x_data對應的y_pred (可和y_data比對)\n",
    "        self.y_predict = []\n",
    "        for row in x_data:\n",
    "            self.pred_row(row, self.tree)\n",
    "        self.y_predict = np.array(self.y_predict)\n",
    "        return self.y_predict \n",
    "    \n",
    "    def show_val_acc(self, pred, y_val):\n",
    "        false = 0 \n",
    "        total = len(y_val)\n",
    "        for p, truth in zip(pred, y_val):\n",
    "            if(p != truth):\n",
    "                false+=1\n",
    "        print(\"accuracy: \", 1.0-float(false/total))\n",
    "    \n",
    "    def return_err(self, pred, y_val): # error between 2 data\n",
    "        false = 0 \n",
    "        total = len(y_val)\n",
    "        for p, truth in zip(pred, y_val):\n",
    "            if(p != truth):\n",
    "                false+=1\n",
    "        return(float(false/total))#float(false/total)\n",
    "    \n",
    "    def important(self, node): #importance of feature\n",
    "        if (type(node)==l_node):\n",
    "            return\n",
    "        print (str(node.split_f))\n",
    "        self.importance[node.split_f[0]] += 1\n",
    "        self.important(node.true)\n",
    "        self.important(node.false)\n",
    "                        \n",
    "        \n",
    "\n",
    "#tree = DecisionTree(max_depth=3)\n",
    "#t = tree.fit(x_data, y_data)\n",
    "#predict =  tree.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Using `criterion=gini`, showing the accuracy score of validation data by `max_depth=3` and `max_depth=10`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = to_nparray(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 3: \n",
      "accuracy:  0.92\n",
      "\n",
      "depth = 10: \n",
      "accuracy:  0.9299999999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_depth3 = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_depth10 = DecisionTree(criterion='gini', max_depth=10)\n",
    "\n",
    "print(\"depth = 3: \")\n",
    "clf_depth3.fit(x_data, y_data)\n",
    "pred_3 =clf_depth3.predict(x_val)\n",
    "clf_depth3.show_val_acc(pred_3, y_val)\n",
    "\n",
    "print('')\n",
    "print(\"depth = 10: \")\n",
    "clf_depth10.fit(x_data, y_data)\n",
    "pred_10 =clf_depth10.predict(x_val)\n",
    "clf_depth10.show_val_acc(pred_10, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_depth10.important(clf_depth10.tree)\n",
    "#print(clf_depth10.importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Using `max_depth=3`, showing the accuracy score of validation data by `criterion=gini` and `criterion=entropy`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = gini: \n",
      "accuracy:  0.92\n",
      "\n",
      "criterion = entropy: \n",
      "accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf_gini = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_entropy = DecisionTree(criterion='entropy', max_depth=3)\n",
    "\n",
    "print(\"criterion = gini: \")\n",
    "clf_gini.fit(x_data, y_data)\n",
    "pred_g =clf_gini.predict(x_val)\n",
    "clf_gini.show_val_acc(pred_g, y_val)\n",
    "\n",
    "print('')\n",
    "print(\"criterion = entropy: \")\n",
    "clf_entropy.fit(x_data, y_data)\n",
    "pred_e =clf_entropy.predict(x_val)\n",
    "clf_entropy.show_val_acc(pred_e, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Your decisition tree scores should over **0.9**. It may suffer from overfitting, if so, you can tune the hyperparameter such as `max_depth`\n",
    "- Note: You should get the same results when re-building the model with the same arguments,  no need to prune the trees\n",
    "- Hint: You can use the recursive method to build the nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the [feature importance](https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/) of your Decision Tree model. You can get the feature importance by counting the feature used for splitting data.\n",
    "\n",
    "- You can simply plot the **counts of feature used** for building tree without normalize the importance. Take the figure below as example, outlook feature has been used for splitting for almost 50 times. Therefore, it has the largest importance\n",
    "\n",
    "![image](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/04/c45-fi-results.jpg?w=481&ssl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot data\n",
    "importances = clf_depth10.importance\n",
    "x_train = train_df.drop(labels=[\"price_range\"], axis=\"columns\")\n",
    "names = x_train.columns.values\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.barh(range(x_data.shape[1]), importances)\n",
    "\n",
    "plt.yticks(range(x_data.shape[1]), names, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "implement the AdaBooest algorithm by using the CART you just implemented from question 2 as base learner. You should implement one arguments for the AdaBooest.\n",
    "1. **n_estimators**: The maximum number of estimators at which boosting is terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(x_data, y_data, D): #resample by D\n",
    "    sample_index = np.random.choice(len(y_data), size=len(y_data), replace=True, p=D)\n",
    "    sample_index.sort()\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in sample_index:\n",
    "        x.append(x_data[i])\n",
    "        y.append(y_data[i])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, n_estimators):\n",
    "        self.n_estimators = n_estimators \n",
    "        self.classifier = []\n",
    "        self.alphalist = []\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        D = [1/len(x_data)]*len(x_data) # init D\n",
    "        self.classifier = []\n",
    "        self.alphalist = []\n",
    "        for t in range(self.n_estimators): # t round, 600 data 1 time\n",
    "            x, y = resample(x_data, y_data, D)\n",
    "            dec_tree = DecisionTree(criterion = 'entropy',max_depth=1)\n",
    "            x = np.array(x)\n",
    "            y = np.array(y)\n",
    "            dec_tree.fit(x, y) \n",
    "            self.classifier.append(dec_tree)\n",
    "            \n",
    "            # call dec_tree.predict = classify using ht\n",
    "            p = dec_tree.predict(x_data)\n",
    "            t_err = dec_tree.return_err(p, y_data)\n",
    "            alpha = np.log((1-t_err)/t_err)*0.5\n",
    "            self.alphalist.append(alpha)\n",
    "            temp_d = []\n",
    "            if(dec_tree.gain!=0):\n",
    "                decide = dec_tree.tree.split_f\n",
    "                for i in range(len(D)):\n",
    "                    if(x_data[i][decide[0]]>=decide[1]):\n",
    "                        x_class = 1\n",
    "                    else:\n",
    "                        x_class = -1\n",
    "                    temp_d.append(D[i]*np.exp(-(alpha*y_data[i]* x_class)))\n",
    "                D = temp_d\n",
    "                D /= np.sum(D) # normalization\n",
    "        \n",
    "\n",
    "    def predict(self, x_data):\n",
    "        preds = []\n",
    "        for t in range(self.n_estimators):\n",
    "            data_pred = self.classifier[t].predict(x_data)\n",
    "            data_pred = np.array(data_pred)\n",
    "            preds.append(self.alphalist[t]*data_pred)\n",
    "        y_prediction = np.sum(preds, axis=0)\n",
    "        y_prediction = np.sign(y_prediction)\n",
    "        return y_prediction\n",
    "\n",
    "    def acc(self, pred, truth):\n",
    "        false = 0\n",
    "        total = len(truth)\n",
    "        for p, t in zip(pred, truth):\n",
    "            \n",
    "            if((p==-1 and t==1)or(p==1 and t==0)):\n",
    "                false +=1\n",
    "        print(\"acc: \", 1-float(false/total))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1\n",
    "Show the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost, n_estimators=10: \n",
      "acc:  0.8591666666666666\n",
      "adaboost, n_estimators=100: \n",
      "acc:  0.8591666666666666\n"
     ]
    }
   ],
   "source": [
    "ada10 = AdaBoost(n_estimators=10)\n",
    "ada10.fit(x_data, y_data)\n",
    "p10 = ada10.predict(x_data)\n",
    "print(\"adaboost, n_estimators=10: \")\n",
    "ada10.acc(p10, y_data)\n",
    "\n",
    "ada100 = AdaBoost(n_estimators=100)\n",
    "ada100.fit(x_data, y_data)\n",
    "p100 = ada10.predict(x_data)\n",
    "print(\"adaboost, n_estimators=100: \")\n",
    "ada100.acc(p100, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "implement the Random Forest algorithm by using the CART you just implemented from question 2. You should implement three arguments for the Random Forest.\n",
    "\n",
    "1. **n_estimators**: The number of trees in the forest. \n",
    "2. **max_features**: The number of random select features to consider when looking for the best split\n",
    "3. **bootstrap**: Whether bootstrap samples are used when building tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(self, n_estimators, max_features, boostrap=True, criterion='gini', max_depth=None):\n",
    "        self.n_estimators = n_estimators \n",
    "        self.classifier = []\n",
    "        self.alphalist = []\n",
    "        self.max_features = int(max_features)\n",
    "        self.boostrap = boostrap\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.pred_result = []\n",
    "\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        D = [1/len(x_data)]*len(x_data) # init D\n",
    "        self.classifier = []\n",
    "        self.alphalist = []\n",
    "        self.pred_result = []\n",
    "        for t in range(self.n_estimators): # t round\n",
    "            x, y = resample(x_data, y_data, D)\n",
    "            \n",
    "            dec_tree = DecisionTree(criterion = self.criterion,max_depth=self.max_depth, forest=True)#decision tree\n",
    "            x = np.array(x)\n",
    "            y = np.array(y)\n",
    "            pool_size = dec_tree.pool(x, y)\n",
    "            dec_tree.feature_pool_index = np.random.choice(pool_size, size=self.max_features, replace=True) # choose index randomly\n",
    "            #print(dec_tree.feature_pool_index)\n",
    "            dec_tree.fit(x, y) \n",
    "            self.classifier.append(dec_tree)\n",
    "            \n",
    "\n",
    "    def predict(self, x_data):\n",
    "        pred_list = []\n",
    "        y_pred = []\n",
    "        for classify in self.classifier:\n",
    "            pred = classify.predict(x_data)\n",
    "            pred_list.append(pred)\n",
    "            #print(pred)\n",
    "            #print(\"-------\")\n",
    "        pred_list = np.array(pred_list)\n",
    "        pred_sum = np.sum(pred_list, axis=0)\n",
    "        half = len(self.classifier)/2\n",
    "        \n",
    "        #print(pred_sum)\n",
    "        for s in pred_sum:\n",
    "            if(s>=half):\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def acc(self, pred, truth):\n",
    "        false = 0\n",
    "        total = len(truth)\n",
    "        for p, t in zip(pred, truth):\n",
    "            \n",
    "            if(p!=t):\n",
    "                false +=1\n",
    "        print(\"acc: \", 1-float(false/total))\n",
    "\n",
    "#f = RandomForest( n_estimators=10, max_features=2000)\n",
    "#f.fit(x_data, y_data)\n",
    "#f_pred = f.predict(x_val)\n",
    "#f.acc(f_pred, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1\n",
    "Using `criterion=gini`, `max_depth=None`, `max_features=sqrt(n_features)`, showing the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_10tree = RandomForest(n_estimators=10, max_features=(1500))\n",
    "clf_10tree = RandomForest(n_estimators=10, max_features=np.sqrt(x_data.shape[1]))\n",
    "clf_10tree.fit(x_data, y_data)\n",
    "\n",
    "#clf_100tree = RandomForest(n_estimators=100, max_features=(1500))\n",
    "clf_100tree = RandomForest(n_estimators=100, max_features=np.sqrt(x_data.shape[1]))\n",
    "clf_100tree.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest, n_estimators=10:\n",
      "acc:  0.91\n",
      "random forest, n_estimators=100:\n",
      "acc:  0.9299999999999999\n"
     ]
    }
   ],
   "source": [
    "pred_10 = clf_10tree.predict(x_val)\n",
    "print(\"random forest, n_estimators=10:\")\n",
    "clf_10tree.acc(pred_10, y_val)\n",
    "\n",
    "print(\"random forest, n_estimators=100:\")\n",
    "pred_100 = clf_100tree.predict(x_val)\n",
    "clf_100tree.acc(pred_100, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2\n",
    "Using `criterion=gini`, `max_depth=None`, `n_estimators=10`, showing the accuracy score of validation data by `max_features=sqrt(n_features)` and `max_features=n_features`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_random_features = RandomForest(n_estimators=10, max_features=np.sqrt(x_data.shape[1]))\n",
    "clf_random_features.fit(x_data, y_data)\n",
    "\n",
    "clf_all_features = RandomForest(n_estimators=10, max_features=x_data.shape[1])\n",
    "clf_all_features.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Use majority votes to get the final prediction, you may get slightly different results when re-building the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest,  max_features=np.sqrt(n_features):\n",
      "acc:  0.8966666666666667\n",
      "random forest,  max_features=n_features:\n",
      "acc:  0.9299999999999999\n"
     ]
    }
   ],
   "source": [
    "pred_r = clf_random_features.predict(x_val)\n",
    "print(\"random forest,  max_features=np.sqrt(n_features):\")\n",
    "clf_random_features.acc(pred_r, y_val)\n",
    "\n",
    "\n",
    "pred_a = clf_all_features.predict(x_val)\n",
    "print(\"random forest,  max_features=n_features:\")\n",
    "clf_all_features.acc(pred_a, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_all_features = RandomForest(n_estimators=100, max_features=x_data.shape[1])\n",
    "clf_all_features.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest,  n=100, max_features=n_features:\n",
      "acc:  0.9366666666666666\n"
     ]
    }
   ],
   "source": [
    "pred_a = clf_all_features.predict(x_val)\n",
    "print(\"random forest,  n=100, max_features=n_features:\")\n",
    "clf_all_features.acc(pred_a, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_all_e = RandomForest(n_estimators=100, max_features=x_data.shape[1], criterion='entropy')\n",
    "clf_all_e.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest,  n=100, max_features=n_features, entropy:\n",
      "acc:  0.9299999999999999\n"
     ]
    }
   ],
   "source": [
    "pred_a = clf_all_e.predict(x_val)\n",
    "print(\"random forest,  n=100, max_features=n_features, entropy:\")\n",
    "clf_all_e.acc(pred_a, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Train and tune your model on a real-world dataset\n",
    "Try you best to get higher accuracy score of your model. After parameter tuning, you can train your model on the full dataset (train + val).\n",
    "- Feature engineering\n",
    "- Hyperparameter tuning\n",
    "- Implement any other ensemble methods, such as gradient boosting. Please note that you **can not** call any package. Also, only ensemble method can be used. Neural network method is not allowed to used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def train_your_model(data):\n",
    "    ## Define your model and training \n",
    "    x_data, y_data = to_nparray(data)\n",
    "    my_model = RandomForest(n_estimators=100, max_features=x_data.shape[1])\n",
    "    my_model.fit(x_data, y_data)\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_df,val_df])\n",
    "my_model = train_your_model(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = pd.read_csv('x_test.csv')\n",
    "x_test = x_test_df.values\n",
    "y_pred = my_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (500, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as pkl_file:\n",
    "    pickle.dump(my_model, pkl_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "np.save(\"y_pred.npy\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary\n",
    "If you have trouble to implement this homework, TA strongly recommend watching [this video](https://www.youtube.com/watch?v=LDRbO9a6XPU), which explains Decision Tree model clearly. But don't copy code from any resources, try to finish this homework by yourself! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT MODIFY CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'y_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 3\u001b[0m y_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39my_test.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mprice_range\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest-set accuarcy score: \u001b[39m\u001b[39m'\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1730\u001b[0m     f,\n\u001b[0;32m   1731\u001b[0m     mode,\n\u001b[0;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1738\u001b[0m )\n\u001b[0;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'y_test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('y_test.csv')['price_range'].values\n",
    "\n",
    "print('Test-set accuarcy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "*** We will check your result for Question 3 manually *** (5 points)\n",
      "22.5\n",
      "30.0\n",
      "35.0\n",
      "40.0\n",
      "RandomForest(n_estimators=10, max_features=n_features) failed\n",
      "Considering the randomness, we will check it manually\n",
      "40.0\n",
      "*** We will check your result for Question 6 manually *** (20 points)\n",
      "Approximate score range: 40.0 ~ 65.0\n",
      "*** This score is only for reference ***\n"
     ]
    }
   ],
   "source": [
    "def discrete_checker(score, thres, clf, name, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "        return score\n",
    "    else:\n",
    "        print(f\"{name} failed\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def patient_checker(score, thres, CLS, kwargs, name,\n",
    "                    x_train, y_train, x_test, y_test, patient=10):\n",
    "    while patient > 0:\n",
    "        patient -= 1\n",
    "        clf = CLS(**kwargs)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "            return score\n",
    "    print(f\"{name} failed\")\n",
    "    print(\"Considering the randomness, we will check it manually\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\"\n",
    "    df = pd.read_csv(\n",
    "        file_url,\n",
    "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "    )\n",
    "\n",
    "    df['Target'] = (df[\"Age\"] > 15).astype(int)\n",
    "    df = df.drop(labels=[\"Age\"], axis=\"columns\")\n",
    "\n",
    "    train_idx = range(0, len(df), 10)\n",
    "    test_idx = range(1, len(df), 20)\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "    x_train = train_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    feature_names = x_train.columns.values\n",
    "    x_train = x_train.values\n",
    "    y_train = train_df['Target'].values\n",
    "\n",
    "    x_test = test_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    x_test = x_test.values\n",
    "    y_test = test_df['Target'].values\n",
    "    return x_train, y_train, x_test, y_test, feature_names\n",
    "\n",
    "\n",
    "score = 0\n",
    "\n",
    "data = np.array([1, 2])\n",
    "if abs(gini(data) - 0.5) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"gini test failed\")\n",
    "\n",
    "if abs(entropy(data) - 1) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"entropy test failed\")\n",
    "\n",
    "x_train, y_train, x_test, y_test, feature_names = load_dataset()\n",
    "\n",
    "score += discrete_checker(5, 0.9337,\n",
    "                          DecisionTree(criterion='gini', max_depth=3),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9036,\n",
    "                          DecisionTree(criterion='gini', max_depth=10),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=10)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9096,\n",
    "                          DecisionTree(criterion='entropy', max_depth=3),\n",
    "                          \"DecisionTree(criterion='entropy', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "print(\"*** We will check your result for Question 3 manually *** (5 points)\")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.91, AdaBoost, {\"n_estimators\": 10},\n",
    "    \"AdaBoost(n_estimators=10)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.87, AdaBoost, {\"n_estimators\": 100},\n",
    "    \"AdaBoost(n_estimators=100)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=10, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 100, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=100, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.92, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": x_train.shape[1]},\n",
    "    \"RandomForest(n_estimators=10, max_features=n_features)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "print(\"*** We will check your result for Question 6 manually *** (20 points)\")\n",
    "print(\"Approximate score range:\", score, \"~\", score + 25)\n",
    "print(\"*** This score is only for reference ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "66eba28a75a64fbe1a9b9c30d27f7c856726c51cbbef86297708eae4ce175db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
