{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CytK5s6yfL0G",
        "outputId": "0dd8a71a-5c6a-402e-e6b2-e89e8e91407c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "#print(os.walk('kaggle/input'))\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'): ## 原為/kaggle/input\n",
        "    for filename in filenames[:3]:\n",
        "        print(os.path.join(dirname, filename))\n",
        "    if len(filenames) > 3:\n",
        "        print(\"...\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:46:59.089399Z",
          "iopub.execute_input": "2022-12-19T11:46:59.089829Z",
          "iopub.status.idle": "2022-12-19T11:47:12.275991Z",
          "shell.execute_reply.started": "2022-12-19T11:46:59.089746Z",
          "shell.execute_reply": "2022-12-19T11:47:12.274738Z"
        },
        "trusted": true,
        "id": "4f0VQ3X_fFmu",
        "outputId": "92470977-ba6f-43c0-f13e-f28e208d321c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/captcha-hacker/sample_submission.csv\n/kaggle/input/captcha-hacker/test/task1/x4LPcV5n6IvLj4vz.png\n/kaggle/input/captcha-hacker/test/task1/W88fVMlAs5IpsXn4.png\n/kaggle/input/captcha-hacker/test/task1/ZWDL6pUMfPu5c9jh.png\n...\n/kaggle/input/captcha-hacker/test/task2/jMalnsI5a5IWxYAi.png\n/kaggle/input/captcha-hacker/test/task2/ihE9HHgyOINGEMcO.png\n/kaggle/input/captcha-hacker/test/task2/ZATEVW3P5s0akZjd.png\n...\n/kaggle/input/captcha-hacker/test/task3/cXBlxYfvQWbiK7dn.png\n/kaggle/input/captcha-hacker/test/task3/5gEp1jR9jNNfuqlk.png\n/kaggle/input/captcha-hacker/test/task3/hEQ0WQtB9B7j8C2f.png\n...\n/kaggle/input/captcha-hacker/train/annotations.csv\n/kaggle/input/captcha-hacker/train/task1/H85RQ6dbWUvLSIDV.png\n/kaggle/input/captcha-hacker/train/task1/n2GC8uY1N4QfvVxe.png\n/kaggle/input/captcha-hacker/train/task1/XOqfRx2R6SnoEjFr.png\n...\n/kaggle/input/captcha-hacker/train/task2/Mr4B2zxXk92hyzn9.png\n/kaggle/input/captcha-hacker/train/task2/SIuRCnlK8VS91FhX.png\n/kaggle/input/captcha-hacker/train/task2/H323tAgDOLPa3ajU.png\n...\n/kaggle/input/captcha-hacker/train/task3/P0zteSLjXm3EcBRx.png\n/kaggle/input/captcha-hacker/train/task3/lhqG7t9j2ZqoqcTD.png\n/kaggle/input/captcha-hacker/train/task3/vGRIi80QVR1gpnjU.png\n...\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import gc\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:47:12.277914Z",
          "iopub.execute_input": "2022-12-19T11:47:12.279864Z",
          "iopub.status.idle": "2022-12-19T11:47:16.497068Z",
          "shell.execute_reply.started": "2022-12-19T11:47:12.279823Z",
          "shell.execute_reply": "2022-12-19T11:47:16.495914Z"
        },
        "trusted": true,
        "id": "Hw62BKJsfFmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\n",
        "TEST_PATH = \"/kaggle/input/captcha-hacker/test\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # device\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:47:16.498592Z",
          "iopub.execute_input": "2022-12-19T11:47:16.499206Z",
          "iopub.status.idle": "2022-12-19T11:47:16.621456Z",
          "shell.execute_reply.started": "2022-12-19T11:47:16.499163Z",
          "shell.execute_reply": "2022-12-19T11:47:16.620080Z"
        },
        "trusted": true,
        "id": "xKWM83Z8fFmx",
        "outputId": "b9bd0e2c-6f2e-4288-96f3-5adc9754294f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Using cuda device\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Task1Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img =torchvision.io.read_image(f\"{self.root}/{filename}\")  #改用torchvision.io \n",
        "        trans = transforms.Compose([\n",
        "            transforms.ToPILImage(), \n",
        "            transforms.Resize(100), # resize img to 100*100\n",
        "            #transforms.ColorJitter(contrast = (1, 10)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalize the channels of the input image tensor\n",
        "         ])\n",
        "        img = trans(img)\n",
        "        \n",
        "        #print(img.shape)\n",
        "        if self.return_filename:\n",
        "            return torch.FloatTensor((img - 128) / 128), filename\n",
        "        else:\n",
        "            return torch.FloatTensor((img - 128) / 128), int(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:47:16.624203Z",
          "iopub.execute_input": "2022-12-19T11:47:16.625187Z",
          "iopub.status.idle": "2022-12-19T11:47:16.635237Z",
          "shell.execute_reply.started": "2022-12-19T11:47:16.625147Z",
          "shell.execute_reply": "2022-12-19T11:47:16.634404Z"
        },
        "trusted": true,
        "id": "HxT33BzYfFmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = []\n",
        "val_data = []\n",
        "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
        "    for row in csv.reader(csvfile, delimiter=','):\n",
        "        if random.random() < 0.7:\n",
        "            train_data.append(row)\n",
        "        else:\n",
        "            val_data.append(row)\n",
        "#print(train_data)\n",
        "train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\n",
        "train_dl = DataLoader(train_ds, batch_size=200, num_workers=2, drop_last=True, shuffle=True)\n",
        "\n",
        "val_ds = Task1Dataset(val_data, root=TRAIN_PATH)\n",
        "val_dl = DataLoader(val_ds, batch_size=200, num_workers=2, drop_last=False, shuffle=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:47:16.636881Z",
          "iopub.execute_input": "2022-12-19T11:47:16.637538Z",
          "iopub.status.idle": "2022-12-19T11:47:16.672379Z",
          "shell.execute_reply.started": "2022-12-19T11:47:16.637501Z",
          "shell.execute_reply": "2022-12-19T11:47:16.671311Z"
        },
        "trusted": true,
        "id": "ohoMC6I3fFmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best1 = 0.0\n",
        "model = models.resnet18(pretrained = True).to(device) # use resnet18 as model, with pretrained weight\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model.fc = nn.Linear(512, 10).to(device) # modify fc layer in resnet18 -> output = 10\n",
        "print(next(model.parameters()).device)\n",
        "\n",
        "for epoch in range(30):\n",
        "    print(f\"Epoch [{epoch}]\")\n",
        "    model.train()\n",
        "    for image, label in train_dl:\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        \n",
        "        pred = model(image)\n",
        "        loss = loss_fn(pred, label)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        del(label)\n",
        "        del(image)\n",
        "        gc.collect()\n",
        "        \n",
        "    sample_count = 0\n",
        "    correct_count = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for image, label in val_dl:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            pred = model(image)\n",
        "            loss = loss_fn(pred, label)\n",
        "\n",
        "            pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "            sample_count += len(image)\n",
        "            correct_count += (label == pred).sum()\n",
        "            del(label)\n",
        "            del(image)\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "    acc = float(correct_count / sample_count)\n",
        "    if((acc > best1) and epoch > 14): \n",
        "        best1 = acc\n",
        "        torch.save(model.state_dict(),'/kaggle/working/model_1.pt') # save model when best result\n",
        "        print(\"update best:\", best1)\n",
        "    print(\"accuracy (validation):\", correct_count / sample_count)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:47:16.674020Z",
          "iopub.execute_input": "2022-12-19T11:47:16.674406Z",
          "iopub.status.idle": "2022-12-19T11:49:36.837942Z",
          "shell.execute_reply.started": "2022-12-19T11:47:16.674368Z",
          "shell.execute_reply": "2022-12-19T11:49:36.836123Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "bfeca6240cec4b459831dc822b41c4d8"
          ]
        },
        "id": "VOdKRV7FfFmy",
        "outputId": "bc6d162b-a838-490c-b886-4a6a04b9f557"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0.00/44.7M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfeca6240cec4b459831dc822b41c4d8"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "cuda:0\nEpoch [0]\naccuracy (validation): tensor(0.0997, device='cuda:0')\nEpoch [1]\naccuracy (validation): tensor(0.1029, device='cuda:0')\nEpoch [2]\naccuracy (validation): tensor(0.1095, device='cuda:0')\nEpoch [3]\naccuracy (validation): tensor(0.0997, device='cuda:0')\nEpoch [4]\naccuracy (validation): tensor(0.1667, device='cuda:0')\nEpoch [5]\naccuracy (validation): tensor(0.7549, device='cuda:0')\nEpoch [6]\naccuracy (validation): tensor(0.1144, device='cuda:0')\nEpoch [7]\naccuracy (validation): tensor(0.0997, device='cuda:0')\nEpoch [8]\naccuracy (validation): tensor(0.1029, device='cuda:0')\nEpoch [9]\naccuracy (validation): tensor(0.1356, device='cuda:0')\nEpoch [10]\naccuracy (validation): tensor(0.9690, device='cuda:0')\nEpoch [11]\naccuracy (validation): tensor(0.8235, device='cuda:0')\nEpoch [12]\naccuracy (validation): tensor(0.6863, device='cuda:0')\nEpoch [13]\naccuracy (validation): tensor(0.7565, device='cuda:0')\nEpoch [14]\naccuracy (validation): tensor(0.5359, device='cuda:0')\nEpoch [15]\nupdate best: 0.3562091588973999\naccuracy (validation): tensor(0.3562, device='cuda:0')\nEpoch [16]\naccuracy (validation): tensor(0.3039, device='cuda:0')\nEpoch [17]\nupdate best: 0.4575163424015045\naccuracy (validation): tensor(0.4575, device='cuda:0')\nEpoch [18]\nupdate best: 0.859477162361145\naccuracy (validation): tensor(0.8595, device='cuda:0')\nEpoch [19]\nupdate best: 0.9575163722038269\naccuracy (validation): tensor(0.9575, device='cuda:0')\nEpoch [20]\nupdate best: 0.9852941036224365\naccuracy (validation): tensor(0.9853, device='cuda:0')\nEpoch [21]\nupdate best: 0.991830050945282\naccuracy (validation): tensor(0.9918, device='cuda:0')\nEpoch [22]\nupdate best: 0.9950980544090271\naccuracy (validation): tensor(0.9951, device='cuda:0')\nEpoch [23]\nupdate best: 0.9967320561408997\naccuracy (validation): tensor(0.9967, device='cuda:0')\nEpoch [24]\nupdate best: 0.9983659982681274\naccuracy (validation): tensor(0.9984, device='cuda:0')\nEpoch [25]\naccuracy (validation): tensor(0.9984, device='cuda:0')\nEpoch [26]\naccuracy (validation): tensor(0.9984, device='cuda:0')\nEpoch [27]\naccuracy (validation): tensor(0.9984, device='cuda:0')\nEpoch [28]\naccuracy (validation): tensor(0.9984, device='cuda:0')\nEpoch [29]\naccuracy (validation): tensor(0.9984, device='cuda:0')\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_process(label): # one-hot encoding\n",
        "    cnt=0\n",
        "    vector = [0] * len(label) * 36 # vector of zeros for one-hot\n",
        "    for ch in label:\n",
        "        if ch.isdigit():\n",
        "            index = (int(ch) + 36*cnt) # when is digit\n",
        "        else:\n",
        "            index = (ord(ch) - 87 + 36*cnt) # when is alpha\n",
        "        cnt+=1\n",
        "        vector[index] = 1 # set corresponding place in vector to 1 \n",
        "    return vector\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:49:36.839415Z",
          "iopub.execute_input": "2022-12-19T11:49:36.840878Z",
          "iopub.status.idle": "2022-12-19T11:49:36.847455Z",
          "shell.execute_reply.started": "2022-12-19T11:49:36.840838Z",
          "shell.execute_reply": "2022-12-19T11:49:36.846576Z"
        },
        "trusted": true,
        "id": "O8SSIfJPfFmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_num(label): \n",
        "    cnt=0\n",
        "    vector = [0] * len(label)\n",
        "    for ch in label:\n",
        "        if ch.isdigit():\n",
        "            vector[cnt] = (int(ch) + 36*cnt)\n",
        "        else:\n",
        "            vector[cnt] = (ord(ch) - 87 + 36*cnt)\n",
        "        cnt+=1\n",
        "    return vector\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:49:36.849035Z",
          "iopub.execute_input": "2022-12-19T11:49:36.849589Z",
          "iopub.status.idle": "2022-12-19T11:49:36.859732Z",
          "shell.execute_reply.started": "2022-12-19T11:49:36.849544Z",
          "shell.execute_reply": "2022-12-19T11:49:36.858818Z"
        },
        "trusted": true,
        "id": "-P52LONXfFmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Task2Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img =torchvision.io.read_image(f\"{self.root}/{filename}\")  #改用torchvision.io \n",
        "        trans = transforms.Compose([\n",
        "            transforms.ToPILImage(), \n",
        "            transforms.Resize(250), # resize to 250*250\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "         ])\n",
        "        img = trans(img)\n",
        "        label_vec = text_process(label)\n",
        "        if self.return_filename:\n",
        "            return torch.FloatTensor(img  / 255), filename\n",
        "        else:\n",
        "            return torch.FloatTensor(img  / 255),  torch.LongTensor(label_vec)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:49:36.861646Z",
          "iopub.execute_input": "2022-12-19T11:49:36.862099Z",
          "iopub.status.idle": "2022-12-19T11:49:36.873158Z",
          "shell.execute_reply.started": "2022-12-19T11:49:36.862060Z",
          "shell.execute_reply": "2022-12-19T11:49:36.872180Z"
        },
        "trusted": true,
        "id": "Vurrcod7fFm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2_data = []\n",
        "val2_data = []\n",
        "\n",
        "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
        "    for row in csv.reader(csvfile, delimiter=','):\n",
        "        if random.random() < 0.8: \n",
        "            train2_data.append(row)\n",
        "        else:\n",
        "            val2_data.append(row)\n",
        "train2_ds = Task2Dataset(train2_data, root=TRAIN_PATH)\n",
        "train2_dl = DataLoader(train2_ds, batch_size=100, num_workers=2, drop_last=True, shuffle=True)\n",
        "\n",
        "val2_ds = Task2Dataset(val2_data, root=TRAIN_PATH)\n",
        "val2_dl = DataLoader(val2_ds, batch_size=100, num_workers=2, drop_last=False, shuffle=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:49:36.877367Z",
          "iopub.execute_input": "2022-12-19T11:49:36.877679Z",
          "iopub.status.idle": "2022-12-19T11:49:36.899641Z",
          "shell.execute_reply.started": "2022-12-19T11:49:36.877635Z",
          "shell.execute_reply": "2022-12-19T11:49:36.898808Z"
        },
        "trusted": true,
        "id": "mloE9SyQfFm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = models.resnet18(pretrained = True).to(device)\n",
        "loss_fn2 = torch.nn.MultiLabelSoftMarginLoss().to(device) # loss function for one-hot encoding\n",
        "model2.fc = nn.Linear(512, 72).to(device) # modify fc layer in resnet18 -> output = 72 (10 digits + 26 alphabets) * 2\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
        "print(next(model2.parameters()).device)\n",
        "\n",
        "#print(model2)\n",
        "best2 = 0.0\n",
        "for epoch in range(30):\n",
        "    print(f\"Epoch [{epoch}]\")\n",
        "    model2.train()\n",
        "    for image, label in train2_dl:\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        \n",
        "        pred = model2(image)\n",
        "        loss = loss_fn2(pred, label)\n",
        "        \n",
        "        optimizer2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        \n",
        "        del(label)\n",
        "        del(image)\n",
        "        #del(label_num)\n",
        "        gc.collect()\n",
        "    sample_count = 0\n",
        "    correct_count = 0\n",
        "    with torch.no_grad():\n",
        "        model2.eval()\n",
        "        for image, label in val2_dl:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "            pred = model2(image)\n",
        "            loss = loss_fn2(pred, label)\n",
        "            batch = len(pred)\n",
        "            for i in range(batch):\n",
        "                one = torch.argmax(pred[i][:36]) # get max(index) of each char\n",
        "                two = torch.argmax(pred[i][36:])\n",
        "                pred_new = torch.zeros(72).to(device) # one-hot\n",
        "                pred_new[one]=1\n",
        "                pred_new[two+36]=1\n",
        "                #還原one-hot\n",
        "\n",
        "                if(label[i].equal(pred_new)): # compare pred & label\n",
        "                    correct_count +=1\n",
        "            sample_count += len(image)\n",
        "            gc.collect()\n",
        "            del(label)\n",
        "            del(image)\n",
        "            torch.cuda.empty_cache()\n",
        "    acc = float(correct_count / sample_count)\n",
        "    if((acc > best2) and epoch > 14):\n",
        "        best2 = acc\n",
        "        torch.save(model2.state_dict(),'/kaggle/working/model_2.pt')\n",
        "        print(\"update best:\", best2)\n",
        "    print(\"accuracy (validation):\", correct_count / sample_count, correct_count, sample_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:49:36.901032Z",
          "iopub.execute_input": "2022-12-19T11:49:36.901382Z",
          "iopub.status.idle": "2022-12-19T11:56:29.019217Z",
          "shell.execute_reply.started": "2022-12-19T11:49:36.901347Z",
          "shell.execute_reply": "2022-12-19T11:56:29.016695Z"
        },
        "trusted": true,
        "id": "Oo_GZE5ZfFm0",
        "outputId": "2d94c966-9864-47ed-c93b-757f85a831b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "cuda:0\nEpoch [0]\naccuracy (validation): 0.0 0 487\nEpoch [1]\naccuracy (validation): 0.0 0 487\nEpoch [2]\naccuracy (validation): 0.3326488706365503 162 487\nEpoch [3]\naccuracy (validation): 0.9240246406570842 450 487\nEpoch [4]\naccuracy (validation): 0.9691991786447639 472 487\nEpoch [5]\naccuracy (validation): 0.9938398357289527 484 487\nEpoch [6]\naccuracy (validation): 1.0 487 487\nEpoch [7]\naccuracy (validation): 0.9958932238193019 485 487\nEpoch [8]\naccuracy (validation): 0.997946611909651 486 487\nEpoch [9]\naccuracy (validation): 0.9958932238193019 485 487\nEpoch [10]\naccuracy (validation): 0.997946611909651 486 487\nEpoch [11]\naccuracy (validation): 1.0 487 487\nEpoch [12]\naccuracy (validation): 1.0 487 487\nEpoch [13]\naccuracy (validation): 0.9958932238193019 485 487\nEpoch [14]\naccuracy (validation): 1.0 487 487\nEpoch [15]\nupdate best: 1.0\naccuracy (validation): 1.0 487 487\nEpoch [16]\naccuracy (validation): 0.9958932238193019 485 487\nEpoch [17]\naccuracy (validation): 0.9958932238193019 485 487\nEpoch [18]\naccuracy (validation): 0.997946611909651 486 487\nEpoch [19]\naccuracy (validation): 0.9958932238193019 485 487\nEpoch [20]\naccuracy (validation): 0.997946611909651 486 487\nEpoch [21]\naccuracy (validation): 0.997946611909651 486 487\nEpoch [22]\naccuracy (validation): 1.0 487 487\nEpoch [23]\naccuracy (validation): 0.997946611909651 486 487\nEpoch [24]\naccuracy (validation): 0.997946611909651 486 487\nEpoch [25]\naccuracy (validation): 0.9958932238193019 485 487\nEpoch [26]\naccuracy (validation): 1.0 487 487\nEpoch [27]\naccuracy (validation): 1.0 487 487\nEpoch [28]\naccuracy (validation): 1.0 487 487\nEpoch [29]\naccuracy (validation): 1.0 487 487\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Task3Dataset(Dataset):\n",
        "    def __init__(self, data, root, return_filename=False):\n",
        "        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n",
        "        self.return_filename = return_filename\n",
        "        self.root = root\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.data[index]\n",
        "        img =torchvision.io.read_image(f\"{self.root}/{filename}\")  #改用torchvision.io \n",
        "        trans = transforms.Compose([\n",
        "            transforms.ToPILImage(), \n",
        "            transforms.Resize(275), # resize img = 275*275\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #normalize \n",
        "         ])\n",
        "        img = trans(img)\n",
        "        label_vec = text_process(label)\n",
        "        \n",
        "        #print(img.shape)\n",
        "        if self.return_filename:\n",
        "            return torch.FloatTensor(img  / 255), filename\n",
        "        else:\n",
        "            return torch.FloatTensor(img  / 255),  torch.LongTensor(label_vec)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:56:29.021383Z",
          "iopub.execute_input": "2022-12-19T11:56:29.021811Z",
          "iopub.status.idle": "2022-12-19T11:56:29.034032Z",
          "shell.execute_reply.started": "2022-12-19T11:56:29.021770Z",
          "shell.execute_reply": "2022-12-19T11:56:29.032839Z"
        },
        "trusted": true,
        "id": "ppWxcYytfFm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train3_data = []\n",
        "val3_data = []\n",
        "\n",
        "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
        "    for row in csv.reader(csvfile, delimiter=','):\n",
        "        if random.random() < 0.9:\n",
        "            train3_data.append(row)\n",
        "        else:\n",
        "            val3_data.append(row)\n",
        "#print(train_data)\n",
        "train3_ds = Task3Dataset(train3_data, root=TRAIN_PATH)\n",
        "train3_dl = DataLoader(train3_ds, batch_size=75, num_workers=2, drop_last=True, shuffle=True)\n",
        "\n",
        "val3_ds = Task3Dataset(val3_data, root=TRAIN_PATH)\n",
        "val3_dl = DataLoader(val3_ds, batch_size=75, num_workers=2, drop_last=False, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:56:29.036853Z",
          "iopub.execute_input": "2022-12-19T11:56:29.037206Z",
          "iopub.status.idle": "2022-12-19T11:56:29.060155Z",
          "shell.execute_reply.started": "2022-12-19T11:56:29.037176Z",
          "shell.execute_reply": "2022-12-19T11:56:29.059184Z"
        },
        "trusted": true,
        "id": "4b46lecdfFm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = models.resnet18(pretrained = True).to(device)\n",
        "loss_fn3 = torch.nn.MultiLabelSoftMarginLoss().to(device) # loss function for one-hot encoding\n",
        "model3.fc = nn.Linear(512, 144).to(device) # modify fc layer in resnet18 -> output = 144 (10 digits + 26 alphabets) * 4\n",
        "optimizer3 = torch.optim.Adam(model3.parameters(), lr=1e-3)\n",
        "print(next(model3.parameters()).device)\n",
        "\n",
        "\n",
        "best3 = 0.0\n",
        "for epoch in range(30):\n",
        "    print(f\"Epoch [{epoch}]\")\n",
        "    model3.train()\n",
        "    for image, label in train3_dl:\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        #label_num = label_num.to(device)\n",
        "        \n",
        "        pred = model3(image)\n",
        "        loss = loss_fn3(pred, label)\n",
        "        #print(\"tra loss: \",loss)\n",
        "        \n",
        "        optimizer3.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer3.step()\n",
        "        \n",
        "        del(label)\n",
        "        del(image)\n",
        "        #del(label_num)\n",
        "        gc.collect()\n",
        "    sample_count = 0\n",
        "    correct_count = 0\n",
        "    with torch.no_grad():\n",
        "        model3.eval()\n",
        "        for image, label in val3_dl:\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            pred = model3(image)\n",
        "            loss = loss_fn3(pred, label)\n",
        "            i=0\n",
        "            batch = len(pred)\n",
        "            for i in range(batch):\n",
        "                one = torch.argmax(pred[i][:36])  # get max(index) of each char\n",
        "                two = torch.argmax(pred[i][36:72])\n",
        "                three = torch.argmax(pred[i][72:108])\n",
        "                four = torch.argmax(pred[i][108:144])\n",
        "                pred_new = torch.zeros(144).to(device)\n",
        "                pred_new[one]=1\n",
        "                pred_new[two+36]=1\n",
        "                pred_new[three+72]=1\n",
        "                pred_new[four+108]=1\n",
        "                #還原one-hot\n",
        "                if(label[i].equal(pred_new)): \n",
        "                    #print(one,two)\n",
        "                    correct_count +=1\n",
        "\n",
        "            sample_count += len(image)\n",
        "            gc.collect()\n",
        "            del(label)\n",
        "            del(image)\n",
        "            torch.cuda.empty_cache()\n",
        "    acc = float(correct_count / sample_count)\n",
        "    if((acc > best3) and epoch > 14):\n",
        "        best3 = acc\n",
        "        torch.save(model3.state_dict(),'/kaggle/working/model_3.pt')\n",
        "        print(\"update best:\", best3)\n",
        "    print(\"accuracy (validation):\", correct_count / sample_count, correct_count, sample_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-19T11:56:29.061815Z",
          "iopub.execute_input": "2022-12-19T11:56:29.062166Z",
          "iopub.status.idle": "2022-12-19T12:07:19.380737Z",
          "shell.execute_reply.started": "2022-12-19T11:56:29.062131Z",
          "shell.execute_reply": "2022-12-19T12:07:19.378418Z"
        },
        "trusted": true,
        "id": "fN3YRhqhfFm1",
        "outputId": "1ea90c20-5f60-4d9e-f332-6dc654447db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "cuda:0\nEpoch [0]\naccuracy (validation): 0.0 0 293\nEpoch [1]\naccuracy (validation): 0.0 0 293\nEpoch [2]\naccuracy (validation): 0.06143344709897611 18 293\nEpoch [3]\naccuracy (validation): 0.2627986348122867 77 293\nEpoch [4]\naccuracy (validation): 0.5767918088737202 169 293\nEpoch [5]\naccuracy (validation): 0.8532423208191127 250 293\nEpoch [6]\naccuracy (validation): 0.9419795221843004 276 293\nEpoch [7]\naccuracy (validation): 0.9590443686006825 281 293\nEpoch [8]\naccuracy (validation): 0.9658703071672355 283 293\nEpoch [9]\naccuracy (validation): 0.9829351535836177 288 293\nEpoch [10]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [11]\naccuracy (validation): 0.9795221843003413 287 293\nEpoch [12]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [13]\naccuracy (validation): 0.9829351535836177 288 293\nEpoch [14]\naccuracy (validation): 0.9761092150170648 286 293\nEpoch [15]\nupdate best: 0.9795221843003413\naccuracy (validation): 0.9795221843003413 287 293\nEpoch [16]\nupdate best: 0.9829351535836177\naccuracy (validation): 0.9829351535836177 288 293\nEpoch [17]\naccuracy (validation): 0.9829351535836177 288 293\nEpoch [18]\naccuracy (validation): 0.9795221843003413 287 293\nEpoch [19]\nupdate best: 0.9863481228668942\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [20]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [21]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [22]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [23]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [24]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [25]\nupdate best: 0.9897610921501706\naccuracy (validation): 0.9897610921501706 290 293\nEpoch [26]\naccuracy (validation): 0.9863481228668942 289 293\nEpoch [27]\naccuracy (validation): 0.9897610921501706 290 293\nEpoch [28]\naccuracy (validation): 0.9897610921501706 290 293\nEpoch [29]\naccuracy (validation): 0.9863481228668942 289 293\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}